{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Spam / Phishing / URL Detection — HD Notebook\n",
        "\n",
        "This notebook:\n",
        "- Loads **three datasets** you attached: `sms_spam.csv`, `emails.csv`, `urls.csv`\n",
        "- Cleans each dataset and saves **cleaned copies**\n",
        "- Merges them into **`data/processed/final.csv`** (the only dataset to submit)\n",
        "- Trains **Logistic Regression + Calibrated Linear SVM** on **TF-IDF (word + char 3–5)** for text\n",
        "- Trains **RandomForest** on **engineered URL features**\n",
        "- Extras: **K-Means** clustering and **IsolationForest** anomaly detection\n",
        "- Evaluation: **Stratified 5-fold CV**, **class_weight='balanced'**, **PR-AUC**, **Precision/Recall/F1 (malicious)**,\n",
        "  **confusion matrix**, and **F₂ threshold tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Paths & Project Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using data from: .\n",
            "Project output: c:\\Users\\Akhi\\Desktop\\New folder\\hd_submission\n"
          ]
        }
      ],
      "source": [
        "import os, re, json, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import (\n",
        "    precision_recall_curve, average_precision_score,\n",
        "    precision_recall_fscore_support, confusion_matrix\n",
        ")\n",
        "from urllib.parse import urlparse\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# Where your CSVs are (auto-tries /mnt/data first, then current folder)\n",
        "CANDIDATES = [\"/mnt/data\", \".\"]\n",
        "for cand in CANDIDATES:\n",
        "    if (os.path.exists(os.path.join(cand, \"sms_spam.csv\"))\n",
        "        and os.path.exists(os.path.join(cand, \"emails.csv\"))\n",
        "        and os.path.exists(os.path.join(cand, \"urls.csv\"))):\n",
        "        DATA_DIR = cand\n",
        "        break\n",
        "else:\n",
        "    DATA_DIR = \".\"\n",
        "\n",
        "# Project output root\n",
        "BASE_DIR = os.path.abspath(\"hd_submission\")\n",
        "RAW_DIR  = os.path.join(BASE_DIR, \"data\", \"raw\")\n",
        "PROC_DIR = os.path.join(BASE_DIR, \"data\", \"processed\")\n",
        "MODEL_DIR= os.path.join(BASE_DIR, \"models\")\n",
        "for d in [RAW_DIR, PROC_DIR, MODEL_DIR]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "SMS_PATH   = os.path.join(DATA_DIR, \"sms_spam.csv\")\n",
        "EMAILS_PATH= os.path.join(DATA_DIR, \"emails.csv\")\n",
        "URLS_PATH  = os.path.join(DATA_DIR, \"urls.csv\")\n",
        "\n",
        "print(\"Using data from:\", DATA_DIR)\n",
        "print(\"Project output:\", BASE_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Loaders & Normalisation (to `text`, `label`, `source`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalise_label(series):\n",
        "    return series.map({\n",
        "        \"spam\":1, \"ham\":0,\n",
        "        \"malicious\":1, \"benign\":0,\n",
        "        \"phish\":1, \"legit\":0, \"legitimate\":0,\n",
        "        \"defacement\":1\n",
        "    }).fillna(series).astype(int)\n",
        "\n",
        "def load_sms(path):\n",
        "    df = pd.read_csv(path, encoding=\"latin-1\")\n",
        "    df.columns = [c.lower() for c in df.columns]\n",
        "    txt = \"text\" if \"text\" in df.columns else (\"message\" if \"message\" in df.columns\n",
        "           else df.select_dtypes(include=[\"object\"]).columns[0])\n",
        "    lab = None\n",
        "    for c in [\"label\", \"category\", \"spam\"]:\n",
        "        if c in df.columns:\n",
        "            lab = c; break\n",
        "    if lab is None:\n",
        "        raise ValueError(\"SMS dataset must contain a label/category/spam column\")\n",
        "    df[\"label\"] = normalise_label(df[lab])\n",
        "    out = df.rename(columns={txt:\"text\"})[[\"text\",\"label\"]].copy()\n",
        "    out = out.drop_duplicates(subset=[\"text\"]).reset_index(drop=True)\n",
        "    out[\"source\"] = \"sms\"\n",
        "    return out\n",
        "\n",
        "def load_emails(path):\n",
        "    df = pd.read_csv(path)\n",
        "    df.columns = [c.lower() for c in df.columns]\n",
        "    txt = None\n",
        "    for c in [\"text\", \"email_text\", \"body\", \"message\", \"content\", \"subject_body\"]:\n",
        "        if c in df.columns:\n",
        "            txt = c; break\n",
        "    if txt is None:\n",
        "        txt = df.select_dtypes(include=[\"object\"]).columns[0]\n",
        "    lab = None\n",
        "    for c in [\"label\", \"spam\", \"is_phish\", \"target\", \"class\"]:\n",
        "        if c in df.columns:\n",
        "            lab = c; break\n",
        "    if lab is None:\n",
        "        raise ValueError(\"Emails dataset missing a label-like column\")\n",
        "    df[\"label\"] = normalise_label(df[lab])\n",
        "    out = df.rename(columns={txt:\"text\"})[[\"text\",\"label\"]].dropna()\n",
        "    out[\"source\"] = \"phish\"\n",
        "    return out\n",
        "\n",
        "def load_urls(path):\n",
        "    df = pd.read_csv(path)\n",
        "    df.columns = [c.lower() for c in df.columns]\n",
        "    if \"url\" in df.columns:\n",
        "        ucol = \"url\"\n",
        "    else:\n",
        "        u_matches = [c for c in df.columns if \"url\" in c]\n",
        "        if not u_matches:\n",
        "            raise ValueError(\"URLs dataset missing a url column\")\n",
        "        ucol = u_matches[0]\n",
        "    lab = None\n",
        "    for c in [\"label\", \"is_malicious\", \"spam\", \"target\", \"class\"]:\n",
        "        if c in df.columns:\n",
        "            lab = c; break\n",
        "    if lab is None:\n",
        "        raise ValueError(\"URLs dataset missing a label-like column\")\n",
        "    df[\"label\"] = normalise_label(df[lab])\n",
        "    out = df.rename(columns={ucol:\"text\"})[[\"text\",\"label\"]].dropna()\n",
        "    out[\"source\"] = \"url\"\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Load All Three Datasets & Preview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "SMS dataset must contain a label/category/spam column",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m sms_df   = \u001b[43mload_sms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSMS_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m email_df = load_emails(EMAILS_PATH)\n\u001b[32m      3\u001b[39m url_df   = load_urls(URLS_PATH)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mload_sms\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     17\u001b[39m         lab = c; \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mSMS dataset must contain a label/category/spam column\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m] = normalise_label(df[lab])\n\u001b[32m     21\u001b[39m out = df.rename(columns={txt:\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m})[[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m]].copy()\n",
            "\u001b[31mValueError\u001b[39m: SMS dataset must contain a label/category/spam column"
          ]
        }
      ],
      "source": [
        "sms_df   = load_sms(SMS_PATH)\n",
        "email_df = load_emails(EMAILS_PATH)\n",
        "url_df   = load_urls(URLS_PATH)\n",
        "\n",
        "print(\"Loaded shapes:\", sms_df.shape, email_df.shape, url_df.shape)\n",
        "display(sms_df.head(3))\n",
        "display(email_df.head(3))\n",
        "display(url_df.head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Clean Each Dataset + Save Clean Copies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_text(s):\n",
        "    s = str(s).lower().strip()\n",
        "    s = re.sub(r\"[\\r\\n\\t]+\", \" \", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s\n",
        "\n",
        "sms_clean    = sms_df.copy();    sms_clean[\"text\"]    = sms_clean[\"text\"].map(clean_text)\n",
        "emails_clean = email_df.copy();  emails_clean[\"text\"] = emails_clean[\"text\"].map(clean_text)\n",
        "urls_clean   = url_df.copy();    urls_clean[\"text\"]   = urls_clean[\"text\"].map(clean_text)\n",
        "\n",
        "sms_clean.to_csv(os.path.join(PROC_DIR, \"sms_clean.csv\"), index=False)\n",
        "emails_clean.to_csv(os.path.join(PROC_DIR, \"emails_clean.csv\"), index=False)\n",
        "urls_clean.to_csv(os.path.join(PROC_DIR, \"urls_clean.csv\"), index=False)\n",
        "print(\"Saved cleaned datasets to:\", PROC_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Merge All → `data/processed/final.csv` (Submission File)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.concat([sms_clean, emails_clean, urls_clean], ignore_index=True)\n",
        "final_path = os.path.join(PROC_DIR, \"final.csv\")\n",
        "df.to_csv(final_path, index=False)\n",
        "print(\"Saved merged final:\", final_path, \"shape:\", df.shape)\n",
        "display(df.source.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Evaluation Helpers (PR‑AUC, F₂ threshold, Confusion Matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_probabilities(y_true, prob_pos, beta=2.0):\n",
        "    precision, recall, thresholds = precision_recall_curve(y_true, prob_pos)\n",
        "    fbeta = (1+beta**2)*(precision*recall)/(beta**2*precision + recall + 1e-12)\n",
        "    best_idx = int(np.nanargmax(fbeta))\n",
        "    best_thr = float(thresholds[max(0, best_idx-1)]) if best_idx > 0 else 0.5\n",
        "    return {\n",
        "        \"best_threshold\": best_thr,\n",
        "        \"best_precision\": float(precision[best_idx]),\n",
        "        \"best_recall\": float(recall[best_idx]),\n",
        "        \"best_fbeta\": float(fbeta[best_idx]),\n",
        "        \"pr_auc\": float(average_precision_score(y_true, prob_pos))\n",
        "    }\n",
        "\n",
        "def report_at_threshold(y_true, prob_pos, thr):\n",
        "    y_pred = (prob_pos >= thr).astype(int)\n",
        "    p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=None, labels=[1])\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
        "    return {\n",
        "        \"threshold\": float(thr),\n",
        "        \"precision_malicious\": float(p[0]),\n",
        "        \"recall_malicious\": float(r[0]),\n",
        "        \"f1_malicious\": float(f1[0]),\n",
        "        \"confusion_matrix[[TN,FP],[FN,TP]]\": cm.tolist()\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Text Models: TF‑IDF (word 1–2 + char 3–5) → LogReg & Calibrated Linear SVM (5-fold CV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text_df = df[df[\"source\"].isin([\"sms\", \"phish\"])].reset_index(drop=True)\n",
        "X_text = text_df[\"text\"].values\n",
        "y_text = text_df[\"label\"].values\n",
        "\n",
        "tfidf_word = TfidfVectorizer(analyzer=\"word\", ngram_range=(1,2), min_df=1)\n",
        "tfidf_char = TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(3,5), min_df=1)\n",
        "Xw = tfidf_word.fit_transform(X_text)\n",
        "Xc = tfidf_char.fit_transform(X_text)\n",
        "Xwc = hstack([Xw, Xc])\n",
        "\n",
        "logreg = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
        "svm_cal = CalibratedClassifierCV(LinearSVC(class_weight=\"balanced\"), method=\"sigmoid\", cv=3)\n",
        "\n",
        "def cv_probs(estimator, X, y, cv=5):\n",
        "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
        "    out = np.zeros_like(y, dtype=float)\n",
        "    for tr, te in skf.split(X, y):\n",
        "        est = estimator\n",
        "        est.fit(X[tr], y[tr])\n",
        "        out[te] = est.predict_proba(X[te])[:,1]\n",
        "    return out\n",
        "\n",
        "prob_log = cv_probs(logreg, Xwc, y_text, cv=5)\n",
        "prob_svm = cv_probs(svm_cal, Xwc, y_text, cv=5)\n",
        "\n",
        "best_log = evaluate_probabilities(y_text, prob_log, beta=2.0)\n",
        "best_svm = evaluate_probabilities(y_text, prob_svm, beta=2.0)\n",
        "rep_log  = report_at_threshold(y_text, prob_log, best_log[\"best_threshold\"])\n",
        "rep_svm  = report_at_threshold(y_text, prob_svm, best_svm[\"best_threshold\"])\n",
        "\n",
        "print(\"=== Text: Logistic Regression ===\")\n",
        "print(json.dumps(best_log, indent=2)); print(json.dumps(rep_log, indent=2))\n",
        "print(\"=== Text: Linear SVM (Calibrated) ===\")\n",
        "print(json.dumps(best_svm, indent=2)); print(json.dumps(rep_svm, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) URL Model: Engineered Lexical Features → RandomForest (5-fold CV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def shannon_entropy(s):\n",
        "    if not s: return 0.0\n",
        "    p = np.array([s.count(c) for c in set(s)], dtype=float); p/=p.sum()\n",
        "    return float(-(p*np.log2(p + 1e-12)).sum())\n",
        "\n",
        "import re\n",
        "def url_features(u):\n",
        "    try:\n",
        "        p = urlparse(u); host=p.netloc or \"\"; pathq=(p.path or \"\")+(\"?\" + p.query if p.query else \"\")\n",
        "        full = (p.netloc or \"\") + (p.path or \"\") + (p.query or \"\")\n",
        "    except:\n",
        "        host=\"\"; pathq=\"\"; full=str(u)\n",
        "    return {\n",
        "        \"len\": len(u),\n",
        "        \"dots\": u.count(\".\"),\n",
        "        \"dashes\": u.count(\"-\"),\n",
        "        \"digits\": sum(ch.isdigit() for ch in u),\n",
        "        \"specials\": sum(ch in \"!@#$%^&*()_+=[]{}|;:'\\\\\\\",<>?/\" for ch in u),\n",
        "        \"entropy\": shannon_entropy(full),\n",
        "        \"num_subdomains\": host.count(\".\"),\n",
        "        \"has_ip\": int(bool(re.search(r\"\\\\b\\\\d{1,3}(?:\\\\.\\\\d{1,3}){3}\\\\b\", host))),\n",
        "        \"tld_len\": len(host.split(\".\")[-1]) if \".\" in host else 0,\n",
        "        \"path_len\": len(pathq),\n",
        "    }\n",
        "\n",
        "url_only = df[df[\"source\"]==\"url\"].reset_index(drop=True)\n",
        "X_url = pd.DataFrame([url_features(u) for u in url_only[\"text\"].tolist()])\n",
        "y_url = url_only[\"label\"].values\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=400, class_weight=\"balanced\", random_state=42, n_jobs=-1)\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "prob_rf = cross_val_predict(rf, X_url, y_url, cv=skf, method=\"predict_proba\")[:,1]\n",
        "\n",
        "best_rf = evaluate_probabilities(y_url, prob_rf, beta=2.0)\n",
        "rep_rf  = report_at_threshold(y_url, prob_rf, best_rf[\"best_threshold\"])\n",
        "\n",
        "print(\"=== URL: RandomForest ===\")\n",
        "print(json.dumps(best_rf, indent=2)); print(json.dumps(rep_rf, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Extra 1 — K‑Means Clustering (Themes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(text_df) >= 6:\n",
        "    tfidf_clu = TfidfVectorizer(analyzer=\"word\", ngram_range=(1,2), min_df=1)\n",
        "    Xc2 = tfidf_clu.fit_transform(text_df[\"text\"].values)\n",
        "    k = min(6, max(2, int(np.sqrt(len(text_df))//2)))\n",
        "    km = KMeans(n_clusters=k, random_state=42, n_init=\"auto\")\n",
        "    labels = km.fit_predict(Xc2)\n",
        "    terms = np.array(tfidf_clu.get_feature_names_out())\n",
        "    order = km.cluster_centers_.argsort()[:, ::-1]\n",
        "    cluster_top_terms = {i: terms[order[i,:10]].tolist() for i in range(k)}\n",
        "    print(\"Top terms per cluster:\")\n",
        "    for i in range(k):\n",
        "        print(i, \":\", cluster_top_terms[i])\n",
        "else:\n",
        "    print(\"[K-Means skipped] Not enough text rows.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Extra 2 — IsolationForest (Anomaly on Benign)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(text_df) >= 10:\n",
        "    tfidf_an = TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(3,5), min_df=1)\n",
        "    Xa = tfidf_an.fit_transform(text_df[\"text\"].values)\n",
        "    ya = text_df[\"label\"].values\n",
        "    benign_mask = (ya==0)\n",
        "    iso = IsolationForest(n_estimators=400, random_state=42, contamination=\"auto\")\n",
        "    iso.fit(Xa[benign_mask].toarray())\n",
        "    scores = iso.decision_function(Xa.toarray())\n",
        "    prob_like = (scores.min() - scores)\n",
        "    prob_like = (prob_like - prob_like.min())/(prob_like.max()-prob_like.min()+1e-12)\n",
        "    best_iso = evaluate_probabilities(ya, prob_like, beta=2.0)\n",
        "    rep_iso  = report_at_threshold(ya, prob_like, best_iso[\"best_threshold\"])\n",
        "    print(\"=== IsolationForest (text) ===\")\n",
        "    print(json.dumps(best_iso, indent=2)); print(json.dumps(rep_iso, indent=2))\n",
        "else:\n",
        "    print(\"[IsolationForest skipped] Not enough text rows.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10) Fit Final Text Model & Save Artifacts (+ threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from joblib import dump\n",
        "tfidf_word_f = TfidfVectorizer(analyzer=\"word\", ngram_range=(1,2), min_df=1)\n",
        "tfidf_char_f = TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(3,5), min_df=1)\n",
        "Xw_f = tfidf_word_f.fit_transform(X_text)\n",
        "Xc_f = tfidf_char_f.fit_transform(X_text)\n",
        "Xwc_f = hstack([Xw_f, Xc_f])\n",
        "\n",
        "svm_final = CalibratedClassifierCV(LinearSVC(class_weight=\"balanced\"), method=\"sigmoid\", cv=3)\n",
        "svm_final.fit(Xwc_f, y_text)\n",
        "\n",
        "dump(tfidf_word_f, os.path.join(MODEL_DIR, \"tfidf_word.joblib\"))\n",
        "dump(tfidf_char_f, os.path.join(MODEL_DIR, \"tfidf_char.joblib\"))\n",
        "dump(svm_final,    os.path.join(MODEL_DIR, \"svm_calibrated.joblib\"))\n",
        "\n",
        "best_thr = 0.5\n",
        "try:\n",
        "    best_thr = float(best_svm[\"best_threshold\"])\n",
        "except:\n",
        "    pass\n",
        "with open(os.path.join(MODEL_DIR, \"threshold.json\"), \"w\") as f:\n",
        "    json.dump({\"f2_threshold\": best_thr}, f, indent=2)\n",
        "\n",
        "print(\"Artifacts saved to:\", MODEL_DIR)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
